{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "LJvXokZD81tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ5S3qS56r_f"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "\n",
        "            predictions = self.predict_proba(X)\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))\n",
        "            db = (1 / n_samples) * np.sum(predictions - y)\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        return self.sigmoid(linear_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y, epochs=1000, learning_rate=0.01):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            y_predicted = self.predict(X)\n",
        "\n",
        "            dw = -(2 / n_samples) * np.dot(X.T, (y - y_predicted))\n",
        "            db = -(2 / n_samples) * np.sum(y - y_predicted)\n",
        "\n",
        "            self.weights -= learning_rate * dw\n",
        "            self.bias -= learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias"
      ],
      "metadata": {
        "id": "96V6qFLi7f47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        num_samples, num_features = X.shape\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        if len(unique_classes) == 1 or (self.max_depth and depth >= self.max_depth):\n",
        "            return {'leaf': True, 'class': unique_classes[0]}\n",
        "\n",
        "        best_feature, best_threshold = self._best_split(X, y, num_features)\n",
        "        if best_feature is None:\n",
        "            return {'leaf': True, 'class': np.bincount(y).argmax()}\n",
        "\n",
        "        left_idx = X[:, best_feature] <= best_threshold\n",
        "        right_idx = ~left_idx\n",
        "\n",
        "        left_subtree = self._build_tree(X[left_idx], y[left_idx], depth + 1)\n",
        "        right_subtree = self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
        "\n",
        "        return {\n",
        "            'leaf': False,\n",
        "            'feature': best_feature,\n",
        "            'threshold': best_threshold,\n",
        "            'left': left_subtree,\n",
        "            'right': right_subtree\n",
        "        }\n",
        "\n",
        "    def _best_split(self, X, y, num_features):\n",
        "        best_gini = float('inf')\n",
        "        best_feature, best_threshold = None, None\n",
        "\n",
        "        for feature in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "                gini = self._gini_index(y[left_mask], y[right_mask])\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _gini_index(self, left_y, right_y):\n",
        "        def gini(y):\n",
        "            m = len(y)\n",
        "            if m == 0:\n",
        "                return 0\n",
        "            class_counts = np.bincount(y)\n",
        "            probs = class_counts / m\n",
        "            return 1 - np.sum(probs ** 2)\n",
        "\n",
        "        left_weight = len(left_y) / (len(left_y) + len(right_y))\n",
        "        right_weight = 1 - left_weight\n",
        "\n",
        "        return left_weight * gini(left_y) + right_weight * gini(right_y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(sample, self.tree) for sample in X])\n",
        "\n",
        "    def _predict_sample(self, sample, node):\n",
        "        if node['leaf']:\n",
        "            return node['class']\n",
        "        if sample[node['feature']] <= node['threshold']:\n",
        "            return self._predict_sample(sample, node['left'])\n",
        "        else:\n",
        "            return self._predict_sample(sample, node['right'])"
      ],
      "metadata": {
        "id": "_RiZEjwe-fO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = [self._predict(x) for x in X_test]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = self.y_train[k_indices]\n",
        "        most_common = np.bincount(k_nearest_labels).argmax()\n",
        "        return most_common"
      ],
      "metadata": {
        "id": "gmqmDa4LEAlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KMeans:\n",
        "    def __init__(self, n_clusters=3, max_iters=100, tol=1e-4, random_state=None):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iters = max_iters\n",
        "        self.tol = tol\n",
        "        self.random_state = random_state\n",
        "        self.centroids = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        if self.random_state:\n",
        "            np.random.seed(self.random_state)\n",
        "\n",
        "        self.centroids = X[np.random.choice(X.shape[0], self.n_clusters, replace=False)]\n",
        "\n",
        "        for _ in range(self.max_iters):\n",
        "            labels = self._assign_clusters(X)\n",
        "\n",
        "            new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(self.n_clusters)])\n",
        "\n",
        "            if np.linalg.norm(self.centroids - new_centroids) < self.tol:\n",
        "                break\n",
        "\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self._assign_clusters(X)\n",
        "\n",
        "    def _assign_clusters(self, X):\n",
        "        distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n",
        "        return np.argmin(distances, axis=1)"
      ],
      "metadata": {
        "id": "p_-4584iEDSq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}